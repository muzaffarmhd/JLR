{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fdq1eBztfod8"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "import pandas as pd\n",
        "import jax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./sample_data/california_housing_train.csv')\n",
        "test = pd.read_csv('./sample_data/california_housing_test.csv')"
      ],
      "metadata": {
        "id": "bRNnIpSSf_p0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "tVz5NL8KgE30",
        "outputId": "5ce2583f-10ae-4c4b-8164-e1262dd52ace"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0        -114.31     34.19                15.0       5612.0          1283.0   \n",
              "1        -114.47     34.40                19.0       7650.0          1901.0   \n",
              "2        -114.56     33.69                17.0        720.0           174.0   \n",
              "3        -114.57     33.64                14.0       1501.0           337.0   \n",
              "4        -114.57     33.57                20.0       1454.0           326.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "16995    -124.26     40.58                52.0       2217.0           394.0   \n",
              "16996    -124.27     40.69                36.0       2349.0           528.0   \n",
              "16997    -124.30     41.84                17.0       2677.0           531.0   \n",
              "16998    -124.30     41.80                19.0       2672.0           552.0   \n",
              "16999    -124.35     40.54                52.0       1820.0           300.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "0          1015.0       472.0         1.4936             66900.0  \n",
              "1          1129.0       463.0         1.8200             80100.0  \n",
              "2           333.0       117.0         1.6509             85700.0  \n",
              "3           515.0       226.0         3.1917             73400.0  \n",
              "4           624.0       262.0         1.9250             65500.0  \n",
              "...           ...         ...            ...                 ...  \n",
              "16995       907.0       369.0         2.3571            111400.0  \n",
              "16996      1194.0       465.0         2.5179             79000.0  \n",
              "16997      1244.0       456.0         3.0313            103600.0  \n",
              "16998      1298.0       478.0         1.9797             85800.0  \n",
              "16999       806.0       270.0         3.0147             94600.0  \n",
              "\n",
              "[17000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db27deeb-5b54-4702-96bd-c9cd4e7e5309\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-114.31</td>\n",
              "      <td>34.19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5612.0</td>\n",
              "      <td>1283.0</td>\n",
              "      <td>1015.0</td>\n",
              "      <td>472.0</td>\n",
              "      <td>1.4936</td>\n",
              "      <td>66900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-114.47</td>\n",
              "      <td>34.40</td>\n",
              "      <td>19.0</td>\n",
              "      <td>7650.0</td>\n",
              "      <td>1901.0</td>\n",
              "      <td>1129.0</td>\n",
              "      <td>463.0</td>\n",
              "      <td>1.8200</td>\n",
              "      <td>80100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-114.56</td>\n",
              "      <td>33.69</td>\n",
              "      <td>17.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>1.6509</td>\n",
              "      <td>85700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.64</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1501.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>515.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>3.1917</td>\n",
              "      <td>73400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-114.57</td>\n",
              "      <td>33.57</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>326.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1.9250</td>\n",
              "      <td>65500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16995</th>\n",
              "      <td>-124.26</td>\n",
              "      <td>40.58</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2217.0</td>\n",
              "      <td>394.0</td>\n",
              "      <td>907.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>2.3571</td>\n",
              "      <td>111400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16996</th>\n",
              "      <td>-124.27</td>\n",
              "      <td>40.69</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2349.0</td>\n",
              "      <td>528.0</td>\n",
              "      <td>1194.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>2.5179</td>\n",
              "      <td>79000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16997</th>\n",
              "      <td>-124.30</td>\n",
              "      <td>41.84</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2677.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>1244.0</td>\n",
              "      <td>456.0</td>\n",
              "      <td>3.0313</td>\n",
              "      <td>103600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16998</th>\n",
              "      <td>-124.30</td>\n",
              "      <td>41.80</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2672.0</td>\n",
              "      <td>552.0</td>\n",
              "      <td>1298.0</td>\n",
              "      <td>478.0</td>\n",
              "      <td>1.9797</td>\n",
              "      <td>85800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16999</th>\n",
              "      <td>-124.35</td>\n",
              "      <td>40.54</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1820.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>3.0147</td>\n",
              "      <td>94600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17000 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db27deeb-5b54-4702-96bd-c9cd4e7e5309')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-db27deeb-5b54-4702-96bd-c9cd4e7e5309 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-db27deeb-5b54-4702-96bd-c9cd4e7e5309');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bf3848bf-f1e4-4e94-a700-0b7846d4b0bf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf3848bf-f1e4-4e94-a700-0b7846d4b0bf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bf3848bf-f1e4-4e94-a700-0b7846d4b0bf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cd2dc15c-92be-44a7-a924-41d617c1c053\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cd2dc15c-92be-44a7-a924-41d617c1c053 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 17000,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.005166408426173,\n        \"min\": -124.35,\n        \"max\": -114.31,\n        \"num_unique_values\": 827,\n        \"samples\": [\n          -117.56,\n          -123.32,\n          -118.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1373397946570734,\n        \"min\": 32.54,\n        \"max\": 41.95,\n        \"num_unique_values\": 840,\n        \"samples\": [\n          38.44,\n          40.79,\n          32.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.586936981660335,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          23.0,\n          52.0,\n          47.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2179.947071452768,\n        \"min\": 2.0,\n        \"max\": 37937.0,\n        \"num_unique_values\": 5533,\n        \"samples\": [\n          3564.0,\n          6955.0,\n          5451.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.49945157986514,\n        \"min\": 1.0,\n        \"max\": 6445.0,\n        \"num_unique_values\": 1848,\n        \"samples\": [\n          729.0,\n          719.0,\n          2075.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1147.852959159525,\n        \"min\": 3.0,\n        \"max\": 35682.0,\n        \"num_unique_values\": 3683,\n        \"samples\": [\n          249.0,\n          1735.0,\n          235.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 384.52084085590013,\n        \"min\": 1.0,\n        \"max\": 6082.0,\n        \"num_unique_values\": 1740,\n        \"samples\": [\n          390.0,\n          1089.0,\n          1351.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.908156518379093,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 11175,\n        \"samples\": [\n          7.2655,\n          5.6293,\n          4.2262\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115983.76438720913,\n        \"min\": 14999.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 3694,\n        \"samples\": [\n          162300.0,\n          346800.0,\n          116700.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "threshold = 0.0001"
      ],
      "metadata": {
        "id": "35g4n6isgmgN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_mean = train['median_house_value'].mean()\n",
        "y_std = train['median_house_value'].std()\n",
        "y_df = train['median_house_value']\n",
        "X_df = train.drop(columns=['median_house_value'])\n",
        "X_df_mean = X_df.mean()\n",
        "X_df_std = X_df.std()\n",
        "X_df = (X_df-X_df.mean())/X_df.std()\n",
        "y_df = (y_df - y_df.mean()) / y_df.std()"
      ],
      "metadata": {
        "id": "RwtLL9IK1BVq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = jnp.array(X_df.values)\n",
        "y = jnp.array(y_df.values).reshape(-1, 1)\n",
        "def loss_fn(w,b,X,y):\n",
        "  pred = jnp.dot(X,w)+ b\n",
        "  return jnp.mean(jnp.square(pred-y))"
      ],
      "metadata": {
        "id": "wW12uxnu3q-_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(w,b,X,y,lr):\n",
        "  dw, db = jax.grad(loss_fn, argnums=(0,1))(w,b,X,y)\n",
        "  new_w = w-lr*dw\n",
        "  new_b = b-lr*db\n",
        "  return new_w,new_b"
      ],
      "metadata": {
        "id": "XZ23HppcVVmM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=jnp.zeros((8,1))\n",
        "b = 0.0\n",
        "epoch=0\n",
        "loss = loss_fn(w,b,X,y)\n",
        "while loss > threshold and epoch < 1000:\n",
        "  print(f\"Training epoch: {epoch}/1000\")\n",
        "  w, b = train_step(w,b,X,y,learning_rate)\n",
        "  loss = loss_fn(w,b,X,y)\n",
        "  print(f\"current_loss {loss}\")\n",
        "  epoch+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EMUbT6nP46av",
        "outputId": "eba2a5ff-2d65-48fd-c981-14f9422c13b7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 0/1000\n",
            "current_loss 0.8078879714012146\n",
            "Training epoch: 1/1000\n",
            "current_loss 0.6853088140487671\n",
            "Training epoch: 2/1000\n",
            "current_loss 0.6051297783851624\n",
            "Training epoch: 3/1000\n",
            "current_loss 0.5520364046096802\n",
            "Training epoch: 4/1000\n",
            "current_loss 0.5163998007774353\n",
            "Training epoch: 5/1000\n",
            "current_loss 0.49208101630210876\n",
            "Training epoch: 6/1000\n",
            "current_loss 0.4751429259777069\n",
            "Training epoch: 7/1000\n",
            "current_loss 0.4630489647388458\n",
            "Training epoch: 8/1000\n",
            "current_loss 0.45415717363357544\n",
            "Training epoch: 9/1000\n",
            "current_loss 0.4474004805088043\n",
            "Training epoch: 10/1000\n",
            "current_loss 0.4420818090438843\n",
            "Training epoch: 11/1000\n",
            "current_loss 0.43774375319480896\n",
            "Training epoch: 12/1000\n",
            "current_loss 0.4340849220752716\n",
            "Training epoch: 13/1000\n",
            "current_loss 0.43090519309043884\n",
            "Training epoch: 14/1000\n",
            "current_loss 0.4280712902545929\n",
            "Training epoch: 15/1000\n",
            "current_loss 0.42549368739128113\n",
            "Training epoch: 16/1000\n",
            "current_loss 0.4231117069721222\n",
            "Training epoch: 17/1000\n",
            "current_loss 0.4208838641643524\n",
            "Training epoch: 18/1000\n",
            "current_loss 0.4187816083431244\n",
            "Training epoch: 19/1000\n",
            "current_loss 0.4167846441268921\n",
            "Training epoch: 20/1000\n",
            "current_loss 0.41487887501716614\n",
            "Training epoch: 21/1000\n",
            "current_loss 0.41305381059646606\n",
            "Training epoch: 22/1000\n",
            "current_loss 0.4113015830516815\n",
            "Training epoch: 23/1000\n",
            "current_loss 0.4096163511276245\n",
            "Training epoch: 24/1000\n",
            "current_loss 0.4079934358596802\n",
            "Training epoch: 25/1000\n",
            "current_loss 0.4064289629459381\n",
            "Training epoch: 26/1000\n",
            "current_loss 0.40491989254951477\n",
            "Training epoch: 27/1000\n",
            "current_loss 0.40346333384513855\n",
            "Training epoch: 28/1000\n",
            "current_loss 0.40205711126327515\n",
            "Training epoch: 29/1000\n",
            "current_loss 0.40069881081581116\n",
            "Training epoch: 30/1000\n",
            "current_loss 0.3993866741657257\n",
            "Training epoch: 31/1000\n",
            "current_loss 0.398118793964386\n",
            "Training epoch: 32/1000\n",
            "current_loss 0.3968935012817383\n",
            "Training epoch: 33/1000\n",
            "current_loss 0.39570924639701843\n",
            "Training epoch: 34/1000\n",
            "current_loss 0.39456436038017273\n",
            "Training epoch: 35/1000\n",
            "current_loss 0.3934575915336609\n",
            "Training epoch: 36/1000\n",
            "current_loss 0.39238741993904114\n",
            "Training epoch: 37/1000\n",
            "current_loss 0.39135265350341797\n",
            "Training epoch: 38/1000\n",
            "current_loss 0.3903519809246063\n",
            "Training epoch: 39/1000\n",
            "current_loss 0.38938426971435547\n",
            "Training epoch: 40/1000\n",
            "current_loss 0.38844823837280273\n",
            "Training epoch: 41/1000\n",
            "current_loss 0.3875429034233093\n",
            "Training epoch: 42/1000\n",
            "current_loss 0.38666707277297974\n",
            "Training epoch: 43/1000\n",
            "current_loss 0.38581982254981995\n",
            "Training epoch: 44/1000\n",
            "current_loss 0.385000079870224\n",
            "Training epoch: 45/1000\n",
            "current_loss 0.3842068612575531\n",
            "Training epoch: 46/1000\n",
            "current_loss 0.38343948125839233\n",
            "Training epoch: 47/1000\n",
            "current_loss 0.38269680738449097\n",
            "Training epoch: 48/1000\n",
            "current_loss 0.3819780647754669\n",
            "Training epoch: 49/1000\n",
            "current_loss 0.3812824785709381\n",
            "Training epoch: 50/1000\n",
            "current_loss 0.3806092441082001\n",
            "Training epoch: 51/1000\n",
            "current_loss 0.3799575865268707\n",
            "Training epoch: 52/1000\n",
            "current_loss 0.379326730966568\n",
            "Training epoch: 53/1000\n",
            "current_loss 0.37871596217155457\n",
            "Training epoch: 54/1000\n",
            "current_loss 0.37812480330467224\n",
            "Training epoch: 55/1000\n",
            "current_loss 0.3775523006916046\n",
            "Training epoch: 56/1000\n",
            "current_loss 0.37699809670448303\n",
            "Training epoch: 57/1000\n",
            "current_loss 0.376461386680603\n",
            "Training epoch: 58/1000\n",
            "current_loss 0.37594151496887207\n",
            "Training epoch: 59/1000\n",
            "current_loss 0.37543824315071106\n",
            "Training epoch: 60/1000\n",
            "current_loss 0.37495070695877075\n",
            "Training epoch: 61/1000\n",
            "current_loss 0.3744785785675049\n",
            "Training epoch: 62/1000\n",
            "current_loss 0.3740212917327881\n",
            "Training epoch: 63/1000\n",
            "current_loss 0.3735782504081726\n",
            "Training epoch: 64/1000\n",
            "current_loss 0.3731490671634674\n",
            "Training epoch: 65/1000\n",
            "current_loss 0.37273332476615906\n",
            "Training epoch: 66/1000\n",
            "current_loss 0.3723304569721222\n",
            "Training epoch: 67/1000\n",
            "current_loss 0.37194013595581055\n",
            "Training epoch: 68/1000\n",
            "current_loss 0.3715619742870331\n",
            "Training epoch: 69/1000\n",
            "current_loss 0.371195524930954\n",
            "Training epoch: 70/1000\n",
            "current_loss 0.3708404004573822\n",
            "Training epoch: 71/1000\n",
            "current_loss 0.3704962134361267\n",
            "Training epoch: 72/1000\n",
            "current_loss 0.3701626658439636\n",
            "Training epoch: 73/1000\n",
            "current_loss 0.36983931064605713\n",
            "Training epoch: 74/1000\n",
            "current_loss 0.3695259690284729\n",
            "Training epoch: 75/1000\n",
            "current_loss 0.3692222237586975\n",
            "Training epoch: 76/1000\n",
            "current_loss 0.3689277172088623\n",
            "Training epoch: 77/1000\n",
            "current_loss 0.36864224076271057\n",
            "Training epoch: 78/1000\n",
            "current_loss 0.36836543679237366\n",
            "Training epoch: 79/1000\n",
            "current_loss 0.36809709668159485\n",
            "Training epoch: 80/1000\n",
            "current_loss 0.3678368628025055\n",
            "Training epoch: 81/1000\n",
            "current_loss 0.36758455634117126\n",
            "Training epoch: 82/1000\n",
            "current_loss 0.3673398792743683\n",
            "Training epoch: 83/1000\n",
            "current_loss 0.36710256338119507\n",
            "Training epoch: 84/1000\n",
            "current_loss 0.3668724596500397\n",
            "Training epoch: 85/1000\n",
            "current_loss 0.3666492700576782\n",
            "Training epoch: 86/1000\n",
            "current_loss 0.3664327561855316\n",
            "Training epoch: 87/1000\n",
            "current_loss 0.3662227690219879\n",
            "Training epoch: 88/1000\n",
            "current_loss 0.3660190999507904\n",
            "Training epoch: 89/1000\n",
            "current_loss 0.3658214807510376\n",
            "Training epoch: 90/1000\n",
            "current_loss 0.36562973260879517\n",
            "Training epoch: 91/1000\n",
            "current_loss 0.36544379591941833\n",
            "Training epoch: 92/1000\n",
            "current_loss 0.3652632236480713\n",
            "Training epoch: 93/1000\n",
            "current_loss 0.3650881350040436\n",
            "Training epoch: 94/1000\n",
            "current_loss 0.36491814255714417\n",
            "Training epoch: 95/1000\n",
            "current_loss 0.36475324630737305\n",
            "Training epoch: 96/1000\n",
            "current_loss 0.3645932078361511\n",
            "Training epoch: 97/1000\n",
            "current_loss 0.36443787813186646\n",
            "Training epoch: 98/1000\n",
            "current_loss 0.3642871379852295\n",
            "Training epoch: 99/1000\n",
            "current_loss 0.36414074897766113\n",
            "Training epoch: 100/1000\n",
            "current_loss 0.363998681306839\n",
            "Training epoch: 101/1000\n",
            "current_loss 0.3638608157634735\n",
            "Training epoch: 102/1000\n",
            "current_loss 0.3637269139289856\n",
            "Training epoch: 103/1000\n",
            "current_loss 0.36359694600105286\n",
            "Training epoch: 104/1000\n",
            "current_loss 0.36347073316574097\n",
            "Training epoch: 105/1000\n",
            "current_loss 0.36334821581840515\n",
            "Training epoch: 106/1000\n",
            "current_loss 0.3632291853427887\n",
            "Training epoch: 107/1000\n",
            "current_loss 0.363113671541214\n",
            "Training epoch: 108/1000\n",
            "current_loss 0.36300140619277954\n",
            "Training epoch: 109/1000\n",
            "current_loss 0.3628924787044525\n",
            "Training epoch: 110/1000\n",
            "current_loss 0.3627866208553314\n",
            "Training epoch: 111/1000\n",
            "current_loss 0.3626837730407715\n",
            "Training epoch: 112/1000\n",
            "current_loss 0.36258387565612793\n",
            "Training epoch: 113/1000\n",
            "current_loss 0.3624868392944336\n",
            "Training epoch: 114/1000\n",
            "current_loss 0.3623925745487213\n",
            "Training epoch: 115/1000\n",
            "current_loss 0.3623010516166687\n",
            "Training epoch: 116/1000\n",
            "current_loss 0.36221203207969666\n",
            "Training epoch: 117/1000\n",
            "current_loss 0.36212557554244995\n",
            "Training epoch: 118/1000\n",
            "current_loss 0.36204153299331665\n",
            "Training epoch: 119/1000\n",
            "current_loss 0.36195990443229675\n",
            "Training epoch: 120/1000\n",
            "current_loss 0.3618805408477783\n",
            "Training epoch: 121/1000\n",
            "current_loss 0.36180344223976135\n",
            "Training epoch: 122/1000\n",
            "current_loss 0.3617284297943115\n",
            "Training epoch: 123/1000\n",
            "current_loss 0.3616555631160736\n",
            "Training epoch: 124/1000\n",
            "current_loss 0.36158472299575806\n",
            "Training epoch: 125/1000\n",
            "current_loss 0.3615158498287201\n",
            "Training epoch: 126/1000\n",
            "current_loss 0.36144885420799255\n",
            "Training epoch: 127/1000\n",
            "current_loss 0.3613837957382202\n",
            "Training epoch: 128/1000\n",
            "current_loss 0.36132046580314636\n",
            "Training epoch: 129/1000\n",
            "current_loss 0.36125895380973816\n",
            "Training epoch: 130/1000\n",
            "current_loss 0.3611990809440613\n",
            "Training epoch: 131/1000\n",
            "current_loss 0.36114081740379333\n",
            "Training epoch: 132/1000\n",
            "current_loss 0.3610842227935791\n",
            "Training epoch: 133/1000\n",
            "current_loss 0.36102911829948425\n",
            "Training epoch: 134/1000\n",
            "current_loss 0.3609755039215088\n",
            "Training epoch: 135/1000\n",
            "current_loss 0.3609234392642975\n",
            "Training epoch: 136/1000\n",
            "current_loss 0.36087271571159363\n",
            "Training epoch: 137/1000\n",
            "current_loss 0.360823392868042\n",
            "Training epoch: 138/1000\n",
            "current_loss 0.360775351524353\n",
            "Training epoch: 139/1000\n",
            "current_loss 0.3607286214828491\n",
            "Training epoch: 140/1000\n",
            "current_loss 0.36068323254585266\n",
            "Training epoch: 141/1000\n",
            "current_loss 0.36063897609710693\n",
            "Training epoch: 142/1000\n",
            "current_loss 0.3605958819389343\n",
            "Training epoch: 143/1000\n",
            "current_loss 0.36055392026901245\n",
            "Training epoch: 144/1000\n",
            "current_loss 0.3605130910873413\n",
            "Training epoch: 145/1000\n",
            "current_loss 0.3604733943939209\n",
            "Training epoch: 146/1000\n",
            "current_loss 0.36043471097946167\n",
            "Training epoch: 147/1000\n",
            "current_loss 0.3603970408439636\n",
            "Training epoch: 148/1000\n",
            "current_loss 0.36036044359207153\n",
            "Training epoch: 149/1000\n",
            "current_loss 0.3603247106075287\n",
            "Training epoch: 150/1000\n",
            "current_loss 0.36028993129730225\n",
            "Training epoch: 151/1000\n",
            "current_loss 0.3602561056613922\n",
            "Training epoch: 152/1000\n",
            "current_loss 0.36022302508354187\n",
            "Training epoch: 153/1000\n",
            "current_loss 0.3601909577846527\n",
            "Training epoch: 154/1000\n",
            "current_loss 0.36015960574150085\n",
            "Training epoch: 155/1000\n",
            "current_loss 0.36012914776802063\n",
            "Training epoch: 156/1000\n",
            "current_loss 0.3600994050502777\n",
            "Training epoch: 157/1000\n",
            "current_loss 0.36007046699523926\n",
            "Training epoch: 158/1000\n",
            "current_loss 0.3600422441959381\n",
            "Training epoch: 159/1000\n",
            "current_loss 0.3600147068500519\n",
            "Training epoch: 160/1000\n",
            "current_loss 0.35998794436454773\n",
            "Training epoch: 161/1000\n",
            "current_loss 0.35996174812316895\n",
            "Training epoch: 162/1000\n",
            "current_loss 0.35993632674217224\n",
            "Training epoch: 163/1000\n",
            "current_loss 0.3599114716053009\n",
            "Training epoch: 164/1000\n",
            "current_loss 0.3598872423171997\n",
            "Training epoch: 165/1000\n",
            "current_loss 0.3598636984825134\n",
            "Training epoch: 166/1000\n",
            "current_loss 0.35984066128730774\n",
            "Training epoch: 167/1000\n",
            "current_loss 0.3598182201385498\n",
            "Training epoch: 168/1000\n",
            "current_loss 0.3597963750362396\n",
            "Training epoch: 169/1000\n",
            "current_loss 0.35977497696876526\n",
            "Training epoch: 170/1000\n",
            "current_loss 0.35975414514541626\n",
            "Training epoch: 171/1000\n",
            "current_loss 0.35973384976387024\n",
            "Training epoch: 172/1000\n",
            "current_loss 0.35971394181251526\n",
            "Training epoch: 173/1000\n",
            "current_loss 0.35969462990760803\n",
            "Training epoch: 174/1000\n",
            "current_loss 0.3596757650375366\n",
            "Training epoch: 175/1000\n",
            "current_loss 0.3596573770046234\n",
            "Training epoch: 176/1000\n",
            "current_loss 0.35963940620422363\n",
            "Training epoch: 177/1000\n",
            "current_loss 0.3596218526363373\n",
            "Training epoch: 178/1000\n",
            "current_loss 0.35960468649864197\n",
            "Training epoch: 179/1000\n",
            "current_loss 0.35958802700042725\n",
            "Training epoch: 180/1000\n",
            "current_loss 0.3595716655254364\n",
            "Training epoch: 181/1000\n",
            "current_loss 0.3595556914806366\n",
            "Training epoch: 182/1000\n",
            "current_loss 0.3595401346683502\n",
            "Training epoch: 183/1000\n",
            "current_loss 0.3595249354839325\n",
            "Training epoch: 184/1000\n",
            "current_loss 0.35951003432273865\n",
            "Training epoch: 185/1000\n",
            "current_loss 0.3594956398010254\n",
            "Training epoch: 186/1000\n",
            "current_loss 0.3594813942909241\n",
            "Training epoch: 187/1000\n",
            "current_loss 0.3594675660133362\n",
            "Training epoch: 188/1000\n",
            "current_loss 0.35945406556129456\n",
            "Training epoch: 189/1000\n",
            "current_loss 0.35944080352783203\n",
            "Training epoch: 190/1000\n",
            "current_loss 0.35942795872688293\n",
            "Training epoch: 191/1000\n",
            "current_loss 0.35941532254219055\n",
            "Training epoch: 192/1000\n",
            "current_loss 0.35940298438072205\n",
            "Training epoch: 193/1000\n",
            "current_loss 0.35939088463783264\n",
            "Training epoch: 194/1000\n",
            "current_loss 0.3593791425228119\n",
            "Training epoch: 195/1000\n",
            "current_loss 0.35936763882637024\n",
            "Training epoch: 196/1000\n",
            "current_loss 0.3593563735485077\n",
            "Training epoch: 197/1000\n",
            "current_loss 0.35934531688690186\n",
            "Training epoch: 198/1000\n",
            "current_loss 0.3593345284461975\n",
            "Training epoch: 199/1000\n",
            "current_loss 0.35932400822639465\n",
            "Training epoch: 200/1000\n",
            "current_loss 0.3593136668205261\n",
            "Training epoch: 201/1000\n",
            "current_loss 0.3593035638332367\n",
            "Training epoch: 202/1000\n",
            "current_loss 0.35929369926452637\n",
            "Training epoch: 203/1000\n",
            "current_loss 0.35928407311439514\n",
            "Training epoch: 204/1000\n",
            "current_loss 0.35927462577819824\n",
            "Training epoch: 205/1000\n",
            "current_loss 0.35926538705825806\n",
            "Training epoch: 206/1000\n",
            "current_loss 0.3592562973499298\n",
            "Training epoch: 207/1000\n",
            "current_loss 0.35924744606018066\n",
            "Training epoch: 208/1000\n",
            "current_loss 0.35923877358436584\n",
            "Training epoch: 209/1000\n",
            "current_loss 0.35923027992248535\n",
            "Training epoch: 210/1000\n",
            "current_loss 0.3592219948768616\n",
            "Training epoch: 211/1000\n",
            "current_loss 0.35921379923820496\n",
            "Training epoch: 212/1000\n",
            "current_loss 0.35920584201812744\n",
            "Training epoch: 213/1000\n",
            "current_loss 0.35919809341430664\n",
            "Training epoch: 214/1000\n",
            "current_loss 0.3591904044151306\n",
            "Training epoch: 215/1000\n",
            "current_loss 0.3591829240322113\n",
            "Training epoch: 216/1000\n",
            "current_loss 0.35917559266090393\n",
            "Training epoch: 217/1000\n",
            "current_loss 0.3591683804988861\n",
            "Training epoch: 218/1000\n",
            "current_loss 0.3591613471508026\n",
            "Training epoch: 219/1000\n",
            "current_loss 0.35915443301200867\n",
            "Training epoch: 220/1000\n",
            "current_loss 0.35914766788482666\n",
            "Training epoch: 221/1000\n",
            "current_loss 0.3591410219669342\n",
            "Training epoch: 222/1000\n",
            "current_loss 0.3591344952583313\n",
            "Training epoch: 223/1000\n",
            "current_loss 0.3591281771659851\n",
            "Training epoch: 224/1000\n",
            "current_loss 0.3591219186782837\n",
            "Training epoch: 225/1000\n",
            "current_loss 0.35911571979522705\n",
            "Training epoch: 226/1000\n",
            "current_loss 0.3591097295284271\n",
            "Training epoch: 227/1000\n",
            "current_loss 0.35910385847091675\n",
            "Training epoch: 228/1000\n",
            "current_loss 0.35909801721572876\n",
            "Training epoch: 229/1000\n",
            "current_loss 0.3590923845767975\n",
            "Training epoch: 230/1000\n",
            "current_loss 0.3590868413448334\n",
            "Training epoch: 231/1000\n",
            "current_loss 0.35908129811286926\n",
            "Training epoch: 232/1000\n",
            "current_loss 0.3590759336948395\n",
            "Training epoch: 233/1000\n",
            "current_loss 0.359070748090744\n",
            "Training epoch: 234/1000\n",
            "current_loss 0.35906556248664856\n",
            "Training epoch: 235/1000\n",
            "current_loss 0.35906049609184265\n",
            "Training epoch: 236/1000\n",
            "current_loss 0.35905539989471436\n",
            "Training epoch: 237/1000\n",
            "current_loss 0.35905060172080994\n",
            "Training epoch: 238/1000\n",
            "current_loss 0.3590458035469055\n",
            "Training epoch: 239/1000\n",
            "current_loss 0.35904112458229065\n",
            "Training epoch: 240/1000\n",
            "current_loss 0.3590364456176758\n",
            "Training epoch: 241/1000\n",
            "current_loss 0.35903188586235046\n",
            "Training epoch: 242/1000\n",
            "current_loss 0.3590274453163147\n",
            "Training epoch: 243/1000\n",
            "current_loss 0.3590230643749237\n",
            "Training epoch: 244/1000\n",
            "current_loss 0.3590187132358551\n",
            "Training epoch: 245/1000\n",
            "current_loss 0.35901451110839844\n",
            "Training epoch: 246/1000\n",
            "current_loss 0.35901033878326416\n",
            "Training epoch: 247/1000\n",
            "current_loss 0.35900625586509705\n",
            "Training epoch: 248/1000\n",
            "current_loss 0.3590022325515747\n",
            "Training epoch: 249/1000\n",
            "current_loss 0.35899823904037476\n",
            "Training epoch: 250/1000\n",
            "current_loss 0.35899436473846436\n",
            "Training epoch: 251/1000\n",
            "current_loss 0.3589906096458435\n",
            "Training epoch: 252/1000\n",
            "current_loss 0.3589867949485779\n",
            "Training epoch: 253/1000\n",
            "current_loss 0.3589831292629242\n",
            "Training epoch: 254/1000\n",
            "current_loss 0.3589794933795929\n",
            "Training epoch: 255/1000\n",
            "current_loss 0.35897597670555115\n",
            "Training epoch: 256/1000\n",
            "current_loss 0.3589724004268646\n",
            "Training epoch: 257/1000\n",
            "current_loss 0.35896897315979004\n",
            "Training epoch: 258/1000\n",
            "current_loss 0.35896560549736023\n",
            "Training epoch: 259/1000\n",
            "current_loss 0.35896220803260803\n",
            "Training epoch: 260/1000\n",
            "current_loss 0.358958899974823\n",
            "Training epoch: 261/1000\n",
            "current_loss 0.3589556813240051\n",
            "Training epoch: 262/1000\n",
            "current_loss 0.35895249247550964\n",
            "Training epoch: 263/1000\n",
            "current_loss 0.35894936323165894\n",
            "Training epoch: 264/1000\n",
            "current_loss 0.358946293592453\n",
            "Training epoch: 265/1000\n",
            "current_loss 0.35894322395324707\n",
            "Training epoch: 266/1000\n",
            "current_loss 0.3589402437210083\n",
            "Training epoch: 267/1000\n",
            "current_loss 0.35893726348876953\n",
            "Training epoch: 268/1000\n",
            "current_loss 0.35893434286117554\n",
            "Training epoch: 269/1000\n",
            "current_loss 0.3589315116405487\n",
            "Training epoch: 270/1000\n",
            "current_loss 0.35892874002456665\n",
            "Training epoch: 271/1000\n",
            "current_loss 0.3589259088039398\n",
            "Training epoch: 272/1000\n",
            "current_loss 0.35892319679260254\n",
            "Training epoch: 273/1000\n",
            "current_loss 0.35892054438591003\n",
            "Training epoch: 274/1000\n",
            "current_loss 0.35891786217689514\n",
            "Training epoch: 275/1000\n",
            "current_loss 0.358915239572525\n",
            "Training epoch: 276/1000\n",
            "current_loss 0.35891270637512207\n",
            "Training epoch: 277/1000\n",
            "current_loss 0.35891014337539673\n",
            "Training epoch: 278/1000\n",
            "current_loss 0.3589076101779938\n",
            "Training epoch: 279/1000\n",
            "current_loss 0.358905166387558\n",
            "Training epoch: 280/1000\n",
            "current_loss 0.35890281200408936\n",
            "Training epoch: 281/1000\n",
            "current_loss 0.3589003086090088\n",
            "Training epoch: 282/1000\n",
            "current_loss 0.35889798402786255\n",
            "Training epoch: 283/1000\n",
            "current_loss 0.3588956296443939\n",
            "Training epoch: 284/1000\n",
            "current_loss 0.35889333486557007\n",
            "Training epoch: 285/1000\n",
            "current_loss 0.3588910698890686\n",
            "Training epoch: 286/1000\n",
            "current_loss 0.3588888943195343\n",
            "Training epoch: 287/1000\n",
            "current_loss 0.3588866591453552\n",
            "Training epoch: 288/1000\n",
            "current_loss 0.35888445377349854\n",
            "Training epoch: 289/1000\n",
            "current_loss 0.358882337808609\n",
            "Training epoch: 290/1000\n",
            "current_loss 0.3588802218437195\n",
            "Training epoch: 291/1000\n",
            "current_loss 0.35887810587882996\n",
            "Training epoch: 292/1000\n",
            "current_loss 0.3588760793209076\n",
            "Training epoch: 293/1000\n",
            "current_loss 0.35887402296066284\n",
            "Training epoch: 294/1000\n",
            "current_loss 0.35887202620506287\n",
            "Training epoch: 295/1000\n",
            "current_loss 0.3588699996471405\n",
            "Training epoch: 296/1000\n",
            "current_loss 0.35886815190315247\n",
            "Training epoch: 297/1000\n",
            "current_loss 0.3588661849498749\n",
            "Training epoch: 298/1000\n",
            "current_loss 0.3588642477989197\n",
            "Training epoch: 299/1000\n",
            "current_loss 0.35886242985725403\n",
            "Training epoch: 300/1000\n",
            "current_loss 0.3588605523109436\n",
            "Training epoch: 301/1000\n",
            "current_loss 0.35885870456695557\n",
            "Training epoch: 302/1000\n",
            "current_loss 0.3588569164276123\n",
            "Training epoch: 303/1000\n",
            "current_loss 0.35885509848594666\n",
            "Training epoch: 304/1000\n",
            "current_loss 0.3588533401489258\n",
            "Training epoch: 305/1000\n",
            "current_loss 0.3588516116142273\n",
            "Training epoch: 306/1000\n",
            "current_loss 0.3588498830795288\n",
            "Training epoch: 307/1000\n",
            "current_loss 0.3588481843471527\n",
            "Training epoch: 308/1000\n",
            "current_loss 0.3588464856147766\n",
            "Training epoch: 309/1000\n",
            "current_loss 0.3588448166847229\n",
            "Training epoch: 310/1000\n",
            "current_loss 0.3588431775569916\n",
            "Training epoch: 311/1000\n",
            "current_loss 0.35884156823158264\n",
            "Training epoch: 312/1000\n",
            "current_loss 0.3588399589061737\n",
            "Training epoch: 313/1000\n",
            "current_loss 0.3588383197784424\n",
            "Training epoch: 314/1000\n",
            "current_loss 0.358836829662323\n",
            "Training epoch: 315/1000\n",
            "current_loss 0.3588353097438812\n",
            "Training epoch: 316/1000\n",
            "current_loss 0.35883376002311707\n",
            "Training epoch: 317/1000\n",
            "current_loss 0.3588322401046753\n",
            "Training epoch: 318/1000\n",
            "current_loss 0.3588307201862335\n",
            "Training epoch: 319/1000\n",
            "current_loss 0.3588292598724365\n",
            "Training epoch: 320/1000\n",
            "current_loss 0.3588278293609619\n",
            "Training epoch: 321/1000\n",
            "current_loss 0.35882633924484253\n",
            "Training epoch: 322/1000\n",
            "current_loss 0.3588249087333679\n",
            "Training epoch: 323/1000\n",
            "current_loss 0.3588235378265381\n",
            "Training epoch: 324/1000\n",
            "current_loss 0.3588221073150635\n",
            "Training epoch: 325/1000\n",
            "current_loss 0.35882073640823364\n",
            "Training epoch: 326/1000\n",
            "current_loss 0.3588193655014038\n",
            "Training epoch: 327/1000\n",
            "current_loss 0.35881802439689636\n",
            "Training epoch: 328/1000\n",
            "current_loss 0.3588166832923889\n",
            "Training epoch: 329/1000\n",
            "current_loss 0.35881537199020386\n",
            "Training epoch: 330/1000\n",
            "current_loss 0.3588140904903412\n",
            "Training epoch: 331/1000\n",
            "current_loss 0.35881277918815613\n",
            "Training epoch: 332/1000\n",
            "current_loss 0.35881152749061584\n",
            "Training epoch: 333/1000\n",
            "current_loss 0.3588102161884308\n",
            "Training epoch: 334/1000\n",
            "current_loss 0.3588089346885681\n",
            "Training epoch: 335/1000\n",
            "current_loss 0.3588077425956726\n",
            "Training epoch: 336/1000\n",
            "current_loss 0.3588065207004547\n",
            "Training epoch: 337/1000\n",
            "current_loss 0.3588052988052368\n",
            "Training epoch: 338/1000\n",
            "current_loss 0.3588040769100189\n",
            "Training epoch: 339/1000\n",
            "current_loss 0.3588028848171234\n",
            "Training epoch: 340/1000\n",
            "current_loss 0.3588017225265503\n",
            "Training epoch: 341/1000\n",
            "current_loss 0.3588005602359772\n",
            "Training epoch: 342/1000\n",
            "current_loss 0.35879939794540405\n",
            "Training epoch: 343/1000\n",
            "current_loss 0.3587982654571533\n",
            "Training epoch: 344/1000\n",
            "current_loss 0.358797162771225\n",
            "Training epoch: 345/1000\n",
            "current_loss 0.35879603028297424\n",
            "Training epoch: 346/1000\n",
            "current_loss 0.3587948977947235\n",
            "Training epoch: 347/1000\n",
            "current_loss 0.35879382491111755\n",
            "Training epoch: 348/1000\n",
            "current_loss 0.3587927222251892\n",
            "Training epoch: 349/1000\n",
            "current_loss 0.358791708946228\n",
            "Training epoch: 350/1000\n",
            "current_loss 0.3587905764579773\n",
            "Training epoch: 351/1000\n",
            "current_loss 0.3587895631790161\n",
            "Training epoch: 352/1000\n",
            "current_loss 0.35878849029541016\n",
            "Training epoch: 353/1000\n",
            "current_loss 0.358787477016449\n",
            "Training epoch: 354/1000\n",
            "current_loss 0.3587864339351654\n",
            "Training epoch: 355/1000\n",
            "current_loss 0.35878539085388184\n",
            "Training epoch: 356/1000\n",
            "current_loss 0.35878440737724304\n",
            "Training epoch: 357/1000\n",
            "current_loss 0.35878339409828186\n",
            "Training epoch: 358/1000\n",
            "current_loss 0.35878247022628784\n",
            "Training epoch: 359/1000\n",
            "current_loss 0.3587813973426819\n",
            "Training epoch: 360/1000\n",
            "current_loss 0.35878050327301025\n",
            "Training epoch: 361/1000\n",
            "current_loss 0.35877951979637146\n",
            "Training epoch: 362/1000\n",
            "current_loss 0.35877859592437744\n",
            "Training epoch: 363/1000\n",
            "current_loss 0.35877764225006104\n",
            "Training epoch: 364/1000\n",
            "current_loss 0.35877668857574463\n",
            "Training epoch: 365/1000\n",
            "current_loss 0.3587757349014282\n",
            "Training epoch: 366/1000\n",
            "current_loss 0.3587748110294342\n",
            "Training epoch: 367/1000\n",
            "current_loss 0.35877397656440735\n",
            "Training epoch: 368/1000\n",
            "current_loss 0.35877302289009094\n",
            "Training epoch: 369/1000\n",
            "current_loss 0.3587721288204193\n",
            "Training epoch: 370/1000\n",
            "current_loss 0.35877126455307007\n",
            "Training epoch: 371/1000\n",
            "current_loss 0.3587704002857208\n",
            "Training epoch: 372/1000\n",
            "current_loss 0.3587695062160492\n",
            "Training epoch: 373/1000\n",
            "current_loss 0.35876864194869995\n",
            "Training epoch: 374/1000\n",
            "current_loss 0.3587677776813507\n",
            "Training epoch: 375/1000\n",
            "current_loss 0.35876691341400146\n",
            "Training epoch: 376/1000\n",
            "current_loss 0.3587660789489746\n",
            "Training epoch: 377/1000\n",
            "current_loss 0.35876527428627014\n",
            "Training epoch: 378/1000\n",
            "current_loss 0.3587644696235657\n",
            "Training epoch: 379/1000\n",
            "current_loss 0.3587636351585388\n",
            "Training epoch: 380/1000\n",
            "current_loss 0.3587627708911896\n",
            "Training epoch: 381/1000\n",
            "current_loss 0.3587620258331299\n",
            "Training epoch: 382/1000\n",
            "current_loss 0.3587612509727478\n",
            "Training epoch: 383/1000\n",
            "current_loss 0.35876044631004333\n",
            "Training epoch: 384/1000\n",
            "current_loss 0.35875967144966125\n",
            "Training epoch: 385/1000\n",
            "current_loss 0.3587588667869568\n",
            "Training epoch: 386/1000\n",
            "current_loss 0.3587580621242523\n",
            "Training epoch: 387/1000\n",
            "current_loss 0.3587573170661926\n",
            "Training epoch: 388/1000\n",
            "current_loss 0.35875654220581055\n",
            "Training epoch: 389/1000\n",
            "current_loss 0.35875579714775085\n",
            "Training epoch: 390/1000\n",
            "current_loss 0.35875508189201355\n",
            "Training epoch: 391/1000\n",
            "current_loss 0.35875436663627625\n",
            "Training epoch: 392/1000\n",
            "current_loss 0.35875359177589417\n",
            "Training epoch: 393/1000\n",
            "current_loss 0.35875290632247925\n",
            "Training epoch: 394/1000\n",
            "current_loss 0.35875213146209717\n",
            "Training epoch: 395/1000\n",
            "current_loss 0.35875141620635986\n",
            "Training epoch: 396/1000\n",
            "current_loss 0.35875070095062256\n",
            "Training epoch: 397/1000\n",
            "current_loss 0.35875001549720764\n",
            "Training epoch: 398/1000\n",
            "current_loss 0.35874930024147034\n",
            "Training epoch: 399/1000\n",
            "current_loss 0.3587486147880554\n",
            "Training epoch: 400/1000\n",
            "current_loss 0.3587479293346405\n",
            "Training epoch: 401/1000\n",
            "current_loss 0.3587472438812256\n",
            "Training epoch: 402/1000\n",
            "current_loss 0.35874658823013306\n",
            "Training epoch: 403/1000\n",
            "current_loss 0.35874590277671814\n",
            "Training epoch: 404/1000\n",
            "current_loss 0.3587452173233032\n",
            "Training epoch: 405/1000\n",
            "current_loss 0.3587445616722107\n",
            "Training epoch: 406/1000\n",
            "current_loss 0.3587438464164734\n",
            "Training epoch: 407/1000\n",
            "current_loss 0.35874325037002563\n",
            "Training epoch: 408/1000\n",
            "current_loss 0.3587425649166107\n",
            "Training epoch: 409/1000\n",
            "current_loss 0.3587419390678406\n",
            "Training epoch: 410/1000\n",
            "current_loss 0.35874131321907043\n",
            "Training epoch: 411/1000\n",
            "current_loss 0.3587406575679779\n",
            "Training epoch: 412/1000\n",
            "current_loss 0.35874003171920776\n",
            "Training epoch: 413/1000\n",
            "current_loss 0.3587394058704376\n",
            "Training epoch: 414/1000\n",
            "current_loss 0.3587387800216675\n",
            "Training epoch: 415/1000\n",
            "current_loss 0.3587382733821869\n",
            "Training epoch: 416/1000\n",
            "current_loss 0.358737587928772\n",
            "Training epoch: 417/1000\n",
            "current_loss 0.3587369918823242\n",
            "Training epoch: 418/1000\n",
            "current_loss 0.35873642563819885\n",
            "Training epoch: 419/1000\n",
            "current_loss 0.3587357699871063\n",
            "Training epoch: 420/1000\n",
            "current_loss 0.35873520374298096\n",
            "Training epoch: 421/1000\n",
            "current_loss 0.3587346374988556\n",
            "Training epoch: 422/1000\n",
            "current_loss 0.35873401165008545\n",
            "Training epoch: 423/1000\n",
            "current_loss 0.35873347520828247\n",
            "Training epoch: 424/1000\n",
            "current_loss 0.35873284935951233\n",
            "Training epoch: 425/1000\n",
            "current_loss 0.3587323725223541\n",
            "Training epoch: 426/1000\n",
            "current_loss 0.358731746673584\n",
            "Training epoch: 427/1000\n",
            "current_loss 0.358731210231781\n",
            "Training epoch: 428/1000\n",
            "current_loss 0.35873061418533325\n",
            "Training epoch: 429/1000\n",
            "current_loss 0.3587300777435303\n",
            "Training epoch: 430/1000\n",
            "current_loss 0.3587295711040497\n",
            "Training epoch: 431/1000\n",
            "current_loss 0.35872897505760193\n",
            "Training epoch: 432/1000\n",
            "current_loss 0.35872843861579895\n",
            "Training epoch: 433/1000\n",
            "current_loss 0.35872793197631836\n",
            "Training epoch: 434/1000\n",
            "current_loss 0.358727365732193\n",
            "Training epoch: 435/1000\n",
            "current_loss 0.35872682929039\n",
            "Training epoch: 436/1000\n",
            "current_loss 0.35872629284858704\n",
            "Training epoch: 437/1000\n",
            "current_loss 0.3587258756160736\n",
            "Training epoch: 438/1000\n",
            "current_loss 0.35872527956962585\n",
            "Training epoch: 439/1000\n",
            "current_loss 0.3587246835231781\n",
            "Training epoch: 440/1000\n",
            "current_loss 0.3587242364883423\n",
            "Training epoch: 441/1000\n",
            "current_loss 0.3587237596511841\n",
            "Training epoch: 442/1000\n",
            "current_loss 0.3587232530117035\n",
            "Training epoch: 443/1000\n",
            "current_loss 0.3587227165699005\n",
            "Training epoch: 444/1000\n",
            "current_loss 0.3587222397327423\n",
            "Training epoch: 445/1000\n",
            "current_loss 0.3587217628955841\n",
            "Training epoch: 446/1000\n",
            "current_loss 0.35872122645378113\n",
            "Training epoch: 447/1000\n",
            "current_loss 0.3587207794189453\n",
            "Training epoch: 448/1000\n",
            "current_loss 0.35872021317481995\n",
            "Training epoch: 449/1000\n",
            "current_loss 0.3587198555469513\n",
            "Training epoch: 450/1000\n",
            "current_loss 0.3587193489074707\n",
            "Training epoch: 451/1000\n",
            "current_loss 0.3587188720703125\n",
            "Training epoch: 452/1000\n",
            "current_loss 0.3587183952331543\n",
            "Training epoch: 453/1000\n",
            "current_loss 0.3587178885936737\n",
            "Training epoch: 454/1000\n",
            "current_loss 0.3587174713611603\n",
            "Training epoch: 455/1000\n",
            "current_loss 0.3587169945240021\n",
            "Training epoch: 456/1000\n",
            "current_loss 0.35871657729148865\n",
            "Training epoch: 457/1000\n",
            "current_loss 0.35871607065200806\n",
            "Training epoch: 458/1000\n",
            "current_loss 0.35871562361717224\n",
            "Training epoch: 459/1000\n",
            "current_loss 0.3587152063846588\n",
            "Training epoch: 460/1000\n",
            "current_loss 0.3587146997451782\n",
            "Training epoch: 461/1000\n",
            "current_loss 0.3587143123149872\n",
            "Training epoch: 462/1000\n",
            "current_loss 0.35871386528015137\n",
            "Training epoch: 463/1000\n",
            "current_loss 0.35871344804763794\n",
            "Training epoch: 464/1000\n",
            "current_loss 0.35871294140815735\n",
            "Training epoch: 465/1000\n",
            "current_loss 0.3587125241756439\n",
            "Training epoch: 466/1000\n",
            "current_loss 0.3587121069431305\n",
            "Training epoch: 467/1000\n",
            "current_loss 0.35871168971061707\n",
            "Training epoch: 468/1000\n",
            "current_loss 0.35871127247810364\n",
            "Training epoch: 469/1000\n",
            "current_loss 0.3587108552455902\n",
            "Training epoch: 470/1000\n",
            "current_loss 0.35871046781539917\n",
            "Training epoch: 471/1000\n",
            "current_loss 0.35871008038520813\n",
            "Training epoch: 472/1000\n",
            "current_loss 0.3587096333503723\n",
            "Training epoch: 473/1000\n",
            "current_loss 0.3587092459201813\n",
            "Training epoch: 474/1000\n",
            "current_loss 0.35870879888534546\n",
            "Training epoch: 475/1000\n",
            "current_loss 0.35870835185050964\n",
            "Training epoch: 476/1000\n",
            "current_loss 0.358707994222641\n",
            "Training epoch: 477/1000\n",
            "current_loss 0.35870757699012756\n",
            "Training epoch: 478/1000\n",
            "current_loss 0.3587072193622589\n",
            "Training epoch: 479/1000\n",
            "current_loss 0.3587068021297455\n",
            "Training epoch: 480/1000\n",
            "current_loss 0.35870641469955444\n",
            "Training epoch: 481/1000\n",
            "current_loss 0.358705997467041\n",
            "Training epoch: 482/1000\n",
            "current_loss 0.35870561003685\n",
            "Training epoch: 483/1000\n",
            "current_loss 0.35870522260665894\n",
            "Training epoch: 484/1000\n",
            "current_loss 0.35870489478111267\n",
            "Training epoch: 485/1000\n",
            "current_loss 0.35870450735092163\n",
            "Training epoch: 486/1000\n",
            "current_loss 0.3587041199207306\n",
            "Training epoch: 487/1000\n",
            "current_loss 0.35870373249053955\n",
            "Training epoch: 488/1000\n",
            "current_loss 0.3587034046649933\n",
            "Training epoch: 489/1000\n",
            "current_loss 0.35870295763015747\n",
            "Training epoch: 490/1000\n",
            "current_loss 0.3587026298046112\n",
            "Training epoch: 491/1000\n",
            "current_loss 0.35870227217674255\n",
            "Training epoch: 492/1000\n",
            "current_loss 0.3587019145488739\n",
            "Training epoch: 493/1000\n",
            "current_loss 0.35870152711868286\n",
            "Training epoch: 494/1000\n",
            "current_loss 0.3587011694908142\n",
            "Training epoch: 495/1000\n",
            "current_loss 0.35870084166526794\n",
            "Training epoch: 496/1000\n",
            "current_loss 0.3587004542350769\n",
            "Training epoch: 497/1000\n",
            "current_loss 0.358700156211853\n",
            "Training epoch: 498/1000\n",
            "current_loss 0.3586997985839844\n",
            "Training epoch: 499/1000\n",
            "current_loss 0.3586994707584381\n",
            "Training epoch: 500/1000\n",
            "current_loss 0.35869908332824707\n",
            "Training epoch: 501/1000\n",
            "current_loss 0.3586987555027008\n",
            "Training epoch: 502/1000\n",
            "current_loss 0.35869842767715454\n",
            "Training epoch: 503/1000\n",
            "current_loss 0.3586980402469635\n",
            "Training epoch: 504/1000\n",
            "current_loss 0.3586978018283844\n",
            "Training epoch: 505/1000\n",
            "current_loss 0.35869741439819336\n",
            "Training epoch: 506/1000\n",
            "current_loss 0.3586970865726471\n",
            "Training epoch: 507/1000\n",
            "current_loss 0.35869672894477844\n",
            "Training epoch: 508/1000\n",
            "current_loss 0.35869643092155457\n",
            "Training epoch: 509/1000\n",
            "current_loss 0.3586961030960083\n",
            "Training epoch: 510/1000\n",
            "current_loss 0.3586958348751068\n",
            "Training epoch: 511/1000\n",
            "current_loss 0.35869547724723816\n",
            "Training epoch: 512/1000\n",
            "current_loss 0.3586951196193695\n",
            "Training epoch: 513/1000\n",
            "current_loss 0.35869482159614563\n",
            "Training epoch: 514/1000\n",
            "current_loss 0.35869452357292175\n",
            "Training epoch: 515/1000\n",
            "current_loss 0.3586941957473755\n",
            "Training epoch: 516/1000\n",
            "current_loss 0.3586938679218292\n",
            "Training epoch: 517/1000\n",
            "current_loss 0.35869356989860535\n",
            "Training epoch: 518/1000\n",
            "current_loss 0.35869327187538147\n",
            "Training epoch: 519/1000\n",
            "current_loss 0.35869300365448\n",
            "Training epoch: 520/1000\n",
            "current_loss 0.3586926758289337\n",
            "Training epoch: 521/1000\n",
            "current_loss 0.3586924076080322\n",
            "Training epoch: 522/1000\n",
            "current_loss 0.3586921691894531\n",
            "Training epoch: 523/1000\n",
            "current_loss 0.3586917221546173\n",
            "Training epoch: 524/1000\n",
            "current_loss 0.3586914837360382\n",
            "Training epoch: 525/1000\n",
            "current_loss 0.35869115591049194\n",
            "Training epoch: 526/1000\n",
            "current_loss 0.35869091749191284\n",
            "Training epoch: 527/1000\n",
            "current_loss 0.35869061946868896\n",
            "Training epoch: 528/1000\n",
            "current_loss 0.3586902916431427\n",
            "Training epoch: 529/1000\n",
            "current_loss 0.3586900234222412\n",
            "Training epoch: 530/1000\n",
            "current_loss 0.3586897552013397\n",
            "Training epoch: 531/1000\n",
            "current_loss 0.35868942737579346\n",
            "Training epoch: 532/1000\n",
            "current_loss 0.35868915915489197\n",
            "Training epoch: 533/1000\n",
            "current_loss 0.35868895053863525\n",
            "Training epoch: 534/1000\n",
            "current_loss 0.358688622713089\n",
            "Training epoch: 535/1000\n",
            "current_loss 0.3586883842945099\n",
            "Training epoch: 536/1000\n",
            "current_loss 0.358688086271286\n",
            "Training epoch: 537/1000\n",
            "current_loss 0.35868775844573975\n",
            "Training epoch: 538/1000\n",
            "current_loss 0.35868754982948303\n",
            "Training epoch: 539/1000\n",
            "current_loss 0.35868725180625916\n",
            "Training epoch: 540/1000\n",
            "current_loss 0.35868698358535767\n",
            "Training epoch: 541/1000\n",
            "current_loss 0.35868674516677856\n",
            "Training epoch: 542/1000\n",
            "current_loss 0.3586864471435547\n",
            "Training epoch: 543/1000\n",
            "current_loss 0.3586862087249756\n",
            "Training epoch: 544/1000\n",
            "current_loss 0.3586859405040741\n",
            "Training epoch: 545/1000\n",
            "current_loss 0.3586856722831726\n",
            "Training epoch: 546/1000\n",
            "current_loss 0.3586854338645935\n",
            "Training epoch: 547/1000\n",
            "current_loss 0.358685165643692\n",
            "Training epoch: 548/1000\n",
            "current_loss 0.3586848974227905\n",
            "Training epoch: 549/1000\n",
            "current_loss 0.35868462920188904\n",
            "Training epoch: 550/1000\n",
            "current_loss 0.3586844205856323\n",
            "Training epoch: 551/1000\n",
            "current_loss 0.3586841821670532\n",
            "Training epoch: 552/1000\n",
            "current_loss 0.35868385434150696\n",
            "Training epoch: 553/1000\n",
            "current_loss 0.35868361592292786\n",
            "Training epoch: 554/1000\n",
            "current_loss 0.35868343710899353\n",
            "Training epoch: 555/1000\n",
            "current_loss 0.35868313908576965\n",
            "Training epoch: 556/1000\n",
            "current_loss 0.35868290066719055\n",
            "Training epoch: 557/1000\n",
            "current_loss 0.35868266224861145\n",
            "Training epoch: 558/1000\n",
            "current_loss 0.3586825132369995\n",
            "Training epoch: 559/1000\n",
            "current_loss 0.35868215560913086\n",
            "Training epoch: 560/1000\n",
            "current_loss 0.35868191719055176\n",
            "Training epoch: 561/1000\n",
            "current_loss 0.3586817681789398\n",
            "Training epoch: 562/1000\n",
            "current_loss 0.35868144035339355\n",
            "Training epoch: 563/1000\n",
            "current_loss 0.35868123173713684\n",
            "Training epoch: 564/1000\n",
            "current_loss 0.3586810231208801\n",
            "Training epoch: 565/1000\n",
            "current_loss 0.35868075489997864\n",
            "Training epoch: 566/1000\n",
            "current_loss 0.3586805760860443\n",
            "Training epoch: 567/1000\n",
            "current_loss 0.3586803376674652\n",
            "Training epoch: 568/1000\n",
            "current_loss 0.3586800992488861\n",
            "Training epoch: 569/1000\n",
            "current_loss 0.358679860830307\n",
            "Training epoch: 570/1000\n",
            "current_loss 0.3586796224117279\n",
            "Training epoch: 571/1000\n",
            "current_loss 0.3586794435977936\n",
            "Training epoch: 572/1000\n",
            "current_loss 0.3586792051792145\n",
            "Training epoch: 573/1000\n",
            "current_loss 0.3586789667606354\n",
            "Training epoch: 574/1000\n",
            "current_loss 0.35867878794670105\n",
            "Training epoch: 575/1000\n",
            "current_loss 0.35867851972579956\n",
            "Training epoch: 576/1000\n",
            "current_loss 0.35867828130722046\n",
            "Training epoch: 577/1000\n",
            "current_loss 0.35867810249328613\n",
            "Training epoch: 578/1000\n",
            "current_loss 0.3586778938770294\n",
            "Training epoch: 579/1000\n",
            "current_loss 0.3586776852607727\n",
            "Training epoch: 580/1000\n",
            "current_loss 0.358677476644516\n",
            "Training epoch: 581/1000\n",
            "current_loss 0.35867729783058167\n",
            "Training epoch: 582/1000\n",
            "current_loss 0.35867705941200256\n",
            "Training epoch: 583/1000\n",
            "current_loss 0.35867682099342346\n",
            "Training epoch: 584/1000\n",
            "current_loss 0.35867664217948914\n",
            "Training epoch: 585/1000\n",
            "current_loss 0.3586764633655548\n",
            "Training epoch: 586/1000\n",
            "current_loss 0.3586762845516205\n",
            "Training epoch: 587/1000\n",
            "current_loss 0.358676016330719\n",
            "Training epoch: 588/1000\n",
            "current_loss 0.35867583751678467\n",
            "Training epoch: 589/1000\n",
            "current_loss 0.35867562890052795\n",
            "Training epoch: 590/1000\n",
            "current_loss 0.358675479888916\n",
            "Training epoch: 591/1000\n",
            "current_loss 0.3586752414703369\n",
            "Training epoch: 592/1000\n",
            "current_loss 0.3586750030517578\n",
            "Training epoch: 593/1000\n",
            "current_loss 0.3586748242378235\n",
            "Training epoch: 594/1000\n",
            "current_loss 0.35867467522621155\n",
            "Training epoch: 595/1000\n",
            "current_loss 0.3586744964122772\n",
            "Training epoch: 596/1000\n",
            "current_loss 0.3586742579936981\n",
            "Training epoch: 597/1000\n",
            "current_loss 0.3586740791797638\n",
            "Training epoch: 598/1000\n",
            "current_loss 0.3586738407611847\n",
            "Training epoch: 599/1000\n",
            "current_loss 0.35867369174957275\n",
            "Training epoch: 600/1000\n",
            "current_loss 0.3586735129356384\n",
            "Training epoch: 601/1000\n",
            "current_loss 0.3586733043193817\n",
            "Training epoch: 602/1000\n",
            "current_loss 0.3586731255054474\n",
            "Training epoch: 603/1000\n",
            "current_loss 0.35867297649383545\n",
            "Training epoch: 604/1000\n",
            "current_loss 0.35867276787757874\n",
            "Training epoch: 605/1000\n",
            "current_loss 0.358672559261322\n",
            "Training epoch: 606/1000\n",
            "current_loss 0.3586724102497101\n",
            "Training epoch: 607/1000\n",
            "current_loss 0.35867223143577576\n",
            "Training epoch: 608/1000\n",
            "current_loss 0.35867205262184143\n",
            "Training epoch: 609/1000\n",
            "current_loss 0.3586719036102295\n",
            "Training epoch: 610/1000\n",
            "current_loss 0.35867172479629517\n",
            "Training epoch: 611/1000\n",
            "current_loss 0.35867154598236084\n",
            "Training epoch: 612/1000\n",
            "current_loss 0.3586713969707489\n",
            "Training epoch: 613/1000\n",
            "current_loss 0.3586711883544922\n",
            "Training epoch: 614/1000\n",
            "current_loss 0.3586709499359131\n",
            "Training epoch: 615/1000\n",
            "current_loss 0.35867083072662354\n",
            "Training epoch: 616/1000\n",
            "current_loss 0.3586706221103668\n",
            "Training epoch: 617/1000\n",
            "current_loss 0.3586704730987549\n",
            "Training epoch: 618/1000\n",
            "current_loss 0.35867032408714294\n",
            "Training epoch: 619/1000\n",
            "current_loss 0.358670175075531\n",
            "Training epoch: 620/1000\n",
            "current_loss 0.35867002606391907\n",
            "Training epoch: 621/1000\n",
            "current_loss 0.35866981744766235\n",
            "Training epoch: 622/1000\n",
            "current_loss 0.35866960883140564\n",
            "Training epoch: 623/1000\n",
            "current_loss 0.3586695194244385\n",
            "Training epoch: 624/1000\n",
            "current_loss 0.35866934061050415\n",
            "Training epoch: 625/1000\n",
            "current_loss 0.3586692214012146\n",
            "Training epoch: 626/1000\n",
            "current_loss 0.3586689829826355\n",
            "Training epoch: 627/1000\n",
            "current_loss 0.35866886377334595\n",
            "Training epoch: 628/1000\n",
            "current_loss 0.3586686849594116\n",
            "Training epoch: 629/1000\n",
            "current_loss 0.35866856575012207\n",
            "Training epoch: 630/1000\n",
            "current_loss 0.35866832733154297\n",
            "Training epoch: 631/1000\n",
            "current_loss 0.3586682379245758\n",
            "Training epoch: 632/1000\n",
            "current_loss 0.35866808891296387\n",
            "Training epoch: 633/1000\n",
            "current_loss 0.35866791009902954\n",
            "Training epoch: 634/1000\n",
            "current_loss 0.3586677610874176\n",
            "Training epoch: 635/1000\n",
            "current_loss 0.3586675822734833\n",
            "Training epoch: 636/1000\n",
            "current_loss 0.3586674928665161\n",
            "Training epoch: 637/1000\n",
            "current_loss 0.3586672842502594\n",
            "Training epoch: 638/1000\n",
            "current_loss 0.3586671054363251\n",
            "Training epoch: 639/1000\n",
            "current_loss 0.3586669862270355\n",
            "Training epoch: 640/1000\n",
            "current_loss 0.3586668372154236\n",
            "Training epoch: 641/1000\n",
            "current_loss 0.35866671800613403\n",
            "Training epoch: 642/1000\n",
            "current_loss 0.3586665689945221\n",
            "Training epoch: 643/1000\n",
            "current_loss 0.35866641998291016\n",
            "Training epoch: 644/1000\n",
            "current_loss 0.35866624116897583\n",
            "Training epoch: 645/1000\n",
            "current_loss 0.3586661219596863\n",
            "Training epoch: 646/1000\n",
            "current_loss 0.35866600275039673\n",
            "Training epoch: 647/1000\n",
            "current_loss 0.3586658239364624\n",
            "Training epoch: 648/1000\n",
            "current_loss 0.3586656451225281\n",
            "Training epoch: 649/1000\n",
            "current_loss 0.3586655557155609\n",
            "Training epoch: 650/1000\n",
            "current_loss 0.35866543650627136\n",
            "Training epoch: 651/1000\n",
            "current_loss 0.3586652874946594\n",
            "Training epoch: 652/1000\n",
            "current_loss 0.3586651682853699\n",
            "Training epoch: 653/1000\n",
            "current_loss 0.35866495966911316\n",
            "Training epoch: 654/1000\n",
            "current_loss 0.358664870262146\n",
            "Training epoch: 655/1000\n",
            "current_loss 0.35866469144821167\n",
            "Training epoch: 656/1000\n",
            "current_loss 0.3586645722389221\n",
            "Training epoch: 657/1000\n",
            "current_loss 0.35866445302963257\n",
            "Training epoch: 658/1000\n",
            "current_loss 0.358664333820343\n",
            "Training epoch: 659/1000\n",
            "current_loss 0.3586641550064087\n",
            "Training epoch: 660/1000\n",
            "current_loss 0.35866403579711914\n",
            "Training epoch: 661/1000\n",
            "current_loss 0.3586639165878296\n",
            "Training epoch: 662/1000\n",
            "current_loss 0.35866379737854004\n",
            "Training epoch: 663/1000\n",
            "current_loss 0.3586637079715729\n",
            "Training epoch: 664/1000\n",
            "current_loss 0.35866352915763855\n",
            "Training epoch: 665/1000\n",
            "current_loss 0.3586634397506714\n",
            "Training epoch: 666/1000\n",
            "current_loss 0.35866326093673706\n",
            "Training epoch: 667/1000\n",
            "current_loss 0.3586631715297699\n",
            "Training epoch: 668/1000\n",
            "current_loss 0.35866302251815796\n",
            "Training epoch: 669/1000\n",
            "current_loss 0.3586629331111908\n",
            "Training epoch: 670/1000\n",
            "current_loss 0.35866281390190125\n",
            "Training epoch: 671/1000\n",
            "current_loss 0.3586626648902893\n",
            "Training epoch: 672/1000\n",
            "current_loss 0.35866257548332214\n",
            "Training epoch: 673/1000\n",
            "current_loss 0.3586623966693878\n",
            "Training epoch: 674/1000\n",
            "current_loss 0.35866227746009827\n",
            "Training epoch: 675/1000\n",
            "current_loss 0.3586621582508087\n",
            "Training epoch: 676/1000\n",
            "current_loss 0.35866206884384155\n",
            "Training epoch: 677/1000\n",
            "current_loss 0.3586619198322296\n",
            "Training epoch: 678/1000\n",
            "current_loss 0.3586617708206177\n",
            "Training epoch: 679/1000\n",
            "current_loss 0.3586616814136505\n",
            "Training epoch: 680/1000\n",
            "current_loss 0.35866156220436096\n",
            "Training epoch: 681/1000\n",
            "current_loss 0.3586615025997162\n",
            "Training epoch: 682/1000\n",
            "current_loss 0.35866138339042664\n",
            "Training epoch: 683/1000\n",
            "current_loss 0.3586612343788147\n",
            "Training epoch: 684/1000\n",
            "current_loss 0.35866111516952515\n",
            "Training epoch: 685/1000\n",
            "current_loss 0.3586609661579132\n",
            "Training epoch: 686/1000\n",
            "current_loss 0.35866084694862366\n",
            "Training epoch: 687/1000\n",
            "current_loss 0.3586607277393341\n",
            "Training epoch: 688/1000\n",
            "current_loss 0.35866063833236694\n",
            "Training epoch: 689/1000\n",
            "current_loss 0.35866057872772217\n",
            "Training epoch: 690/1000\n",
            "current_loss 0.3586604595184326\n",
            "Training epoch: 691/1000\n",
            "current_loss 0.35866037011146545\n",
            "Training epoch: 692/1000\n",
            "current_loss 0.35866019129753113\n",
            "Training epoch: 693/1000\n",
            "current_loss 0.3586600720882416\n",
            "Training epoch: 694/1000\n",
            "current_loss 0.358659952878952\n",
            "Training epoch: 695/1000\n",
            "current_loss 0.35865986347198486\n",
            "Training epoch: 696/1000\n",
            "current_loss 0.3586598038673401\n",
            "Training epoch: 697/1000\n",
            "current_loss 0.35865965485572815\n",
            "Training epoch: 698/1000\n",
            "current_loss 0.358659565448761\n",
            "Training epoch: 699/1000\n",
            "current_loss 0.3586594760417938\n",
            "Training epoch: 700/1000\n",
            "current_loss 0.35865938663482666\n",
            "Training epoch: 701/1000\n",
            "current_loss 0.3586592376232147\n",
            "Training epoch: 702/1000\n",
            "current_loss 0.35865914821624756\n",
            "Training epoch: 703/1000\n",
            "current_loss 0.3586590588092804\n",
            "Training epoch: 704/1000\n",
            "current_loss 0.3586589992046356\n",
            "Training epoch: 705/1000\n",
            "current_loss 0.3586588501930237\n",
            "Training epoch: 706/1000\n",
            "current_loss 0.3586587607860565\n",
            "Training epoch: 707/1000\n",
            "current_loss 0.3586586117744446\n",
            "Training epoch: 708/1000\n",
            "current_loss 0.3586585223674774\n",
            "Training epoch: 709/1000\n",
            "current_loss 0.35865843296051025\n",
            "Training epoch: 710/1000\n",
            "current_loss 0.3586583435535431\n",
            "Training epoch: 711/1000\n",
            "current_loss 0.35865822434425354\n",
            "Training epoch: 712/1000\n",
            "current_loss 0.35865816473960876\n",
            "Training epoch: 713/1000\n",
            "current_loss 0.3586580455303192\n",
            "Training epoch: 714/1000\n",
            "current_loss 0.35865795612335205\n",
            "Training epoch: 715/1000\n",
            "current_loss 0.3586578667163849\n",
            "Training epoch: 716/1000\n",
            "current_loss 0.35865768790245056\n",
            "Training epoch: 717/1000\n",
            "current_loss 0.3586576581001282\n",
            "Training epoch: 718/1000\n",
            "current_loss 0.3586575388908386\n",
            "Training epoch: 719/1000\n",
            "current_loss 0.35865744948387146\n",
            "Training epoch: 720/1000\n",
            "current_loss 0.3586573600769043\n",
            "Training epoch: 721/1000\n",
            "current_loss 0.3586573004722595\n",
            "Training epoch: 722/1000\n",
            "current_loss 0.35865724086761475\n",
            "Training epoch: 723/1000\n",
            "current_loss 0.3586571514606476\n",
            "Training epoch: 724/1000\n",
            "current_loss 0.35865703225135803\n",
            "Training epoch: 725/1000\n",
            "current_loss 0.3586569130420685\n",
            "Training epoch: 726/1000\n",
            "current_loss 0.3586568534374237\n",
            "Training epoch: 727/1000\n",
            "current_loss 0.35865673422813416\n",
            "Training epoch: 728/1000\n",
            "current_loss 0.3586566746234894\n",
            "Training epoch: 729/1000\n",
            "current_loss 0.35865655541419983\n",
            "Training epoch: 730/1000\n",
            "current_loss 0.35865646600723267\n",
            "Training epoch: 731/1000\n",
            "current_loss 0.3586564362049103\n",
            "Training epoch: 732/1000\n",
            "current_loss 0.3586563169956207\n",
            "Training epoch: 733/1000\n",
            "current_loss 0.3586561977863312\n",
            "Training epoch: 734/1000\n",
            "current_loss 0.358656108379364\n",
            "Training epoch: 735/1000\n",
            "current_loss 0.35865601897239685\n",
            "Training epoch: 736/1000\n",
            "current_loss 0.3586559593677521\n",
            "Training epoch: 737/1000\n",
            "current_loss 0.3586558401584625\n",
            "Training epoch: 738/1000\n",
            "current_loss 0.35865578055381775\n",
            "Training epoch: 739/1000\n",
            "current_loss 0.35865575075149536\n",
            "Training epoch: 740/1000\n",
            "current_loss 0.3586556613445282\n",
            "Training epoch: 741/1000\n",
            "current_loss 0.35865551233291626\n",
            "Training epoch: 742/1000\n",
            "current_loss 0.3586554527282715\n",
            "Training epoch: 743/1000\n",
            "current_loss 0.3586553931236267\n",
            "Training epoch: 744/1000\n",
            "current_loss 0.35865524411201477\n",
            "Training epoch: 745/1000\n",
            "current_loss 0.3586552143096924\n",
            "Training epoch: 746/1000\n",
            "current_loss 0.35865509510040283\n",
            "Training epoch: 747/1000\n",
            "current_loss 0.35865506529808044\n",
            "Training epoch: 748/1000\n",
            "current_loss 0.3586549758911133\n",
            "Training epoch: 749/1000\n",
            "current_loss 0.3586548864841461\n",
            "Training epoch: 750/1000\n",
            "current_loss 0.35865482687950134\n",
            "Training epoch: 751/1000\n",
            "current_loss 0.3586547374725342\n",
            "Training epoch: 752/1000\n",
            "current_loss 0.358654648065567\n",
            "Training epoch: 753/1000\n",
            "current_loss 0.35865455865859985\n",
            "Training epoch: 754/1000\n",
            "current_loss 0.3586544692516327\n",
            "Training epoch: 755/1000\n",
            "current_loss 0.3586544692516327\n",
            "Training epoch: 756/1000\n",
            "current_loss 0.35865435004234314\n",
            "Training epoch: 757/1000\n",
            "current_loss 0.358654260635376\n",
            "Training epoch: 758/1000\n",
            "current_loss 0.3586542010307312\n",
            "Training epoch: 759/1000\n",
            "current_loss 0.3586541414260864\n",
            "Training epoch: 760/1000\n",
            "current_loss 0.35865405201911926\n",
            "Training epoch: 761/1000\n",
            "current_loss 0.3586539626121521\n",
            "Training epoch: 762/1000\n",
            "current_loss 0.3586539328098297\n",
            "Training epoch: 763/1000\n",
            "current_loss 0.35865381360054016\n",
            "Training epoch: 764/1000\n",
            "current_loss 0.3586537539958954\n",
            "Training epoch: 765/1000\n",
            "current_loss 0.3586536645889282\n",
            "Training epoch: 766/1000\n",
            "current_loss 0.35865360498428345\n",
            "Training epoch: 767/1000\n",
            "current_loss 0.35865354537963867\n",
            "Training epoch: 768/1000\n",
            "current_loss 0.3586534857749939\n",
            "Training epoch: 769/1000\n",
            "current_loss 0.35865336656570435\n",
            "Training epoch: 770/1000\n",
            "current_loss 0.35865333676338196\n",
            "Training epoch: 771/1000\n",
            "current_loss 0.3586532771587372\n",
            "Training epoch: 772/1000\n",
            "current_loss 0.3586532175540924\n",
            "Training epoch: 773/1000\n",
            "current_loss 0.35865312814712524\n",
            "Training epoch: 774/1000\n",
            "current_loss 0.35865306854248047\n",
            "Training epoch: 775/1000\n",
            "current_loss 0.3586529791355133\n",
            "Training epoch: 776/1000\n",
            "current_loss 0.35865291953086853\n",
            "Training epoch: 777/1000\n",
            "current_loss 0.35865285992622375\n",
            "Training epoch: 778/1000\n",
            "current_loss 0.3586527109146118\n",
            "Training epoch: 779/1000\n",
            "current_loss 0.3586527109146118\n",
            "Training epoch: 780/1000\n",
            "current_loss 0.35865268111228943\n",
            "Training epoch: 781/1000\n",
            "current_loss 0.35865262150764465\n",
            "Training epoch: 782/1000\n",
            "current_loss 0.3586525619029999\n",
            "Training epoch: 783/1000\n",
            "current_loss 0.3586524426937103\n",
            "Training epoch: 784/1000\n",
            "current_loss 0.35865238308906555\n",
            "Training epoch: 785/1000\n",
            "current_loss 0.3586522936820984\n",
            "Training epoch: 786/1000\n",
            "current_loss 0.358652263879776\n",
            "Training epoch: 787/1000\n",
            "current_loss 0.35865217447280884\n",
            "Training epoch: 788/1000\n",
            "current_loss 0.35865214467048645\n",
            "Training epoch: 789/1000\n",
            "current_loss 0.3586519956588745\n",
            "Training epoch: 790/1000\n",
            "current_loss 0.3586519956588745\n",
            "Training epoch: 791/1000\n",
            "current_loss 0.35865190625190735\n",
            "Training epoch: 792/1000\n",
            "current_loss 0.35865190625190735\n",
            "Training epoch: 793/1000\n",
            "current_loss 0.3586518466472626\n",
            "Training epoch: 794/1000\n",
            "current_loss 0.358651727437973\n",
            "Training epoch: 795/1000\n",
            "current_loss 0.35865166783332825\n",
            "Training epoch: 796/1000\n",
            "current_loss 0.35865163803100586\n",
            "Training epoch: 797/1000\n",
            "current_loss 0.3586515784263611\n",
            "Training epoch: 798/1000\n",
            "current_loss 0.3586514890193939\n",
            "Training epoch: 799/1000\n",
            "current_loss 0.3586515188217163\n",
            "Training epoch: 800/1000\n",
            "current_loss 0.35865136981010437\n",
            "Training epoch: 801/1000\n",
            "current_loss 0.35865136981010437\n",
            "Training epoch: 802/1000\n",
            "current_loss 0.3586512804031372\n",
            "Training epoch: 803/1000\n",
            "current_loss 0.35865119099617004\n",
            "Training epoch: 804/1000\n",
            "current_loss 0.35865113139152527\n",
            "Training epoch: 805/1000\n",
            "current_loss 0.3586511015892029\n",
            "Training epoch: 806/1000\n",
            "current_loss 0.3586510717868805\n",
            "Training epoch: 807/1000\n",
            "current_loss 0.35865098237991333\n",
            "Training epoch: 808/1000\n",
            "current_loss 0.35865095257759094\n",
            "Training epoch: 809/1000\n",
            "current_loss 0.3586508631706238\n",
            "Training epoch: 810/1000\n",
            "current_loss 0.358650803565979\n",
            "Training epoch: 811/1000\n",
            "current_loss 0.358650803565979\n",
            "Training epoch: 812/1000\n",
            "current_loss 0.35865071415901184\n",
            "Training epoch: 813/1000\n",
            "current_loss 0.35865065455436707\n",
            "Training epoch: 814/1000\n",
            "current_loss 0.3586505651473999\n",
            "Training epoch: 815/1000\n",
            "current_loss 0.3586505353450775\n",
            "Training epoch: 816/1000\n",
            "current_loss 0.3586505055427551\n",
            "Training epoch: 817/1000\n",
            "current_loss 0.3586503863334656\n",
            "Training epoch: 818/1000\n",
            "current_loss 0.3586503863334656\n",
            "Training epoch: 819/1000\n",
            "current_loss 0.3586503267288208\n",
            "Training epoch: 820/1000\n",
            "current_loss 0.3586503267288208\n",
            "Training epoch: 821/1000\n",
            "current_loss 0.35865023732185364\n",
            "Training epoch: 822/1000\n",
            "current_loss 0.35865017771720886\n",
            "Training epoch: 823/1000\n",
            "current_loss 0.3586501181125641\n",
            "Training epoch: 824/1000\n",
            "current_loss 0.3586500585079193\n",
            "Training epoch: 825/1000\n",
            "current_loss 0.3586500585079193\n",
            "Training epoch: 826/1000\n",
            "current_loss 0.35864993929862976\n",
            "Training epoch: 827/1000\n",
            "current_loss 0.3586499094963074\n",
            "Training epoch: 828/1000\n",
            "current_loss 0.358649879693985\n",
            "Training epoch: 829/1000\n",
            "current_loss 0.3586498200893402\n",
            "Training epoch: 830/1000\n",
            "current_loss 0.35864973068237305\n",
            "Training epoch: 831/1000\n",
            "current_loss 0.35864967107772827\n",
            "Training epoch: 832/1000\n",
            "current_loss 0.35864967107772827\n",
            "Training epoch: 833/1000\n",
            "current_loss 0.35864967107772827\n",
            "Training epoch: 834/1000\n",
            "current_loss 0.3586495518684387\n",
            "Training epoch: 835/1000\n",
            "current_loss 0.3586495518684387\n",
            "Training epoch: 836/1000\n",
            "current_loss 0.35864949226379395\n",
            "Training epoch: 837/1000\n",
            "current_loss 0.35864949226379395\n",
            "Training epoch: 838/1000\n",
            "current_loss 0.3586493730545044\n",
            "Training epoch: 839/1000\n",
            "current_loss 0.3586493134498596\n",
            "Training epoch: 840/1000\n",
            "current_loss 0.35864928364753723\n",
            "Training epoch: 841/1000\n",
            "current_loss 0.35864925384521484\n",
            "Training epoch: 842/1000\n",
            "current_loss 0.35864919424057007\n",
            "Training epoch: 843/1000\n",
            "current_loss 0.3586491644382477\n",
            "Training epoch: 844/1000\n",
            "current_loss 0.3586490750312805\n",
            "Training epoch: 845/1000\n",
            "current_loss 0.35864904522895813\n",
            "Training epoch: 846/1000\n",
            "current_loss 0.35864901542663574\n",
            "Training epoch: 847/1000\n",
            "current_loss 0.35864898562431335\n",
            "Training epoch: 848/1000\n",
            "current_loss 0.3586489260196686\n",
            "Training epoch: 849/1000\n",
            "current_loss 0.3586488366127014\n",
            "Training epoch: 850/1000\n",
            "current_loss 0.3586488366127014\n",
            "Training epoch: 851/1000\n",
            "current_loss 0.3586488366127014\n",
            "Training epoch: 852/1000\n",
            "current_loss 0.3586486876010895\n",
            "Training epoch: 853/1000\n",
            "current_loss 0.35864871740341187\n",
            "Training epoch: 854/1000\n",
            "current_loss 0.3586486577987671\n",
            "Training epoch: 855/1000\n",
            "current_loss 0.3586485981941223\n",
            "Training epoch: 856/1000\n",
            "current_loss 0.3586485683917999\n",
            "Training epoch: 857/1000\n",
            "current_loss 0.35864850878715515\n",
            "Training epoch: 858/1000\n",
            "current_loss 0.3586484491825104\n",
            "Training epoch: 859/1000\n",
            "current_loss 0.358648419380188\n",
            "Training epoch: 860/1000\n",
            "current_loss 0.3586484491825104\n",
            "Training epoch: 861/1000\n",
            "current_loss 0.3586483299732208\n",
            "Training epoch: 862/1000\n",
            "current_loss 0.3586483299732208\n",
            "Training epoch: 863/1000\n",
            "current_loss 0.35864827036857605\n",
            "Training epoch: 864/1000\n",
            "current_loss 0.35864824056625366\n",
            "Training epoch: 865/1000\n",
            "current_loss 0.3586481809616089\n",
            "Training epoch: 866/1000\n",
            "current_loss 0.3586481511592865\n",
            "Training epoch: 867/1000\n",
            "current_loss 0.3586480915546417\n",
            "Training epoch: 868/1000\n",
            "current_loss 0.35864806175231934\n",
            "Training epoch: 869/1000\n",
            "current_loss 0.35864803194999695\n",
            "Training epoch: 870/1000\n",
            "current_loss 0.35864803194999695\n",
            "Training epoch: 871/1000\n",
            "current_loss 0.3586479425430298\n",
            "Training epoch: 872/1000\n",
            "current_loss 0.3586479425430298\n",
            "Training epoch: 873/1000\n",
            "current_loss 0.3586478531360626\n",
            "Training epoch: 874/1000\n",
            "current_loss 0.358647882938385\n",
            "Training epoch: 875/1000\n",
            "current_loss 0.35864779353141785\n",
            "Training epoch: 876/1000\n",
            "current_loss 0.35864779353141785\n",
            "Training epoch: 877/1000\n",
            "current_loss 0.3586477041244507\n",
            "Training epoch: 878/1000\n",
            "current_loss 0.3586477041244507\n",
            "Training epoch: 879/1000\n",
            "current_loss 0.3586476147174835\n",
            "Training epoch: 880/1000\n",
            "current_loss 0.3586476147174835\n",
            "Training epoch: 881/1000\n",
            "current_loss 0.35864755511283875\n",
            "Training epoch: 882/1000\n",
            "current_loss 0.35864752531051636\n",
            "Training epoch: 883/1000\n",
            "current_loss 0.35864749550819397\n",
            "Training epoch: 884/1000\n",
            "current_loss 0.3586474359035492\n",
            "Training epoch: 885/1000\n",
            "current_loss 0.3586474657058716\n",
            "Training epoch: 886/1000\n",
            "current_loss 0.3586473762989044\n",
            "Training epoch: 887/1000\n",
            "current_loss 0.35864734649658203\n",
            "Training epoch: 888/1000\n",
            "current_loss 0.35864728689193726\n",
            "Training epoch: 889/1000\n",
            "current_loss 0.35864725708961487\n",
            "Training epoch: 890/1000\n",
            "current_loss 0.35864725708961487\n",
            "Training epoch: 891/1000\n",
            "current_loss 0.3586471676826477\n",
            "Training epoch: 892/1000\n",
            "current_loss 0.3586471676826477\n",
            "Training epoch: 893/1000\n",
            "current_loss 0.3586471676826477\n",
            "Training epoch: 894/1000\n",
            "current_loss 0.35864710807800293\n",
            "Training epoch: 895/1000\n",
            "current_loss 0.35864710807800293\n",
            "Training epoch: 896/1000\n",
            "current_loss 0.35864704847335815\n",
            "Training epoch: 897/1000\n",
            "current_loss 0.3586469888687134\n",
            "Training epoch: 898/1000\n",
            "current_loss 0.3586469888687134\n",
            "Training epoch: 899/1000\n",
            "current_loss 0.3586469292640686\n",
            "Training epoch: 900/1000\n",
            "current_loss 0.3586468994617462\n",
            "Training epoch: 901/1000\n",
            "current_loss 0.35864686965942383\n",
            "Training epoch: 902/1000\n",
            "current_loss 0.35864681005477905\n",
            "Training epoch: 903/1000\n",
            "current_loss 0.35864681005477905\n",
            "Training epoch: 904/1000\n",
            "current_loss 0.35864678025245667\n",
            "Training epoch: 905/1000\n",
            "current_loss 0.3586467206478119\n",
            "Training epoch: 906/1000\n",
            "current_loss 0.3586467206478119\n",
            "Training epoch: 907/1000\n",
            "current_loss 0.3586466312408447\n",
            "Training epoch: 908/1000\n",
            "current_loss 0.3586466312408447\n",
            "Training epoch: 909/1000\n",
            "current_loss 0.35864657163619995\n",
            "Training epoch: 910/1000\n",
            "current_loss 0.35864654183387756\n",
            "Training epoch: 911/1000\n",
            "current_loss 0.35864654183387756\n",
            "Training epoch: 912/1000\n",
            "current_loss 0.35864654183387756\n",
            "Training epoch: 913/1000\n",
            "current_loss 0.3586464524269104\n",
            "Training epoch: 914/1000\n",
            "current_loss 0.3586464524269104\n",
            "Training epoch: 915/1000\n",
            "current_loss 0.3586463928222656\n",
            "Training epoch: 916/1000\n",
            "current_loss 0.35864636301994324\n",
            "Training epoch: 917/1000\n",
            "current_loss 0.35864636301994324\n",
            "Training epoch: 918/1000\n",
            "current_loss 0.35864636301994324\n",
            "Training epoch: 919/1000\n",
            "current_loss 0.35864636301994324\n",
            "Training epoch: 920/1000\n",
            "current_loss 0.35864630341529846\n",
            "Training epoch: 921/1000\n",
            "current_loss 0.3586462736129761\n",
            "Training epoch: 922/1000\n",
            "current_loss 0.3586462438106537\n",
            "Training epoch: 923/1000\n",
            "current_loss 0.3586461842060089\n",
            "Training epoch: 924/1000\n",
            "current_loss 0.3586461842060089\n",
            "Training epoch: 925/1000\n",
            "current_loss 0.35864612460136414\n",
            "Training epoch: 926/1000\n",
            "current_loss 0.35864609479904175\n",
            "Training epoch: 927/1000\n",
            "current_loss 0.35864609479904175\n",
            "Training epoch: 928/1000\n",
            "current_loss 0.35864606499671936\n",
            "Training epoch: 929/1000\n",
            "current_loss 0.358646035194397\n",
            "Training epoch: 930/1000\n",
            "current_loss 0.3586459755897522\n",
            "Training epoch: 931/1000\n",
            "current_loss 0.3586459755897522\n",
            "Training epoch: 932/1000\n",
            "current_loss 0.3586459159851074\n",
            "Training epoch: 933/1000\n",
            "current_loss 0.3586459159851074\n",
            "Training epoch: 934/1000\n",
            "current_loss 0.35864585638046265\n",
            "Training epoch: 935/1000\n",
            "current_loss 0.35864585638046265\n",
            "Training epoch: 936/1000\n",
            "current_loss 0.35864579677581787\n",
            "Training epoch: 937/1000\n",
            "current_loss 0.3586457669734955\n",
            "Training epoch: 938/1000\n",
            "current_loss 0.3586457669734955\n",
            "Training epoch: 939/1000\n",
            "current_loss 0.3586457371711731\n",
            "Training epoch: 940/1000\n",
            "current_loss 0.3586457073688507\n",
            "Training epoch: 941/1000\n",
            "current_loss 0.35864564776420593\n",
            "Training epoch: 942/1000\n",
            "current_loss 0.35864561796188354\n",
            "Training epoch: 943/1000\n",
            "current_loss 0.35864561796188354\n",
            "Training epoch: 944/1000\n",
            "current_loss 0.35864561796188354\n",
            "Training epoch: 945/1000\n",
            "current_loss 0.35864555835723877\n",
            "Training epoch: 946/1000\n",
            "current_loss 0.35864555835723877\n",
            "Training epoch: 947/1000\n",
            "current_loss 0.358645498752594\n",
            "Training epoch: 948/1000\n",
            "current_loss 0.35864555835723877\n",
            "Training epoch: 949/1000\n",
            "current_loss 0.358645498752594\n",
            "Training epoch: 950/1000\n",
            "current_loss 0.3586454689502716\n",
            "Training epoch: 951/1000\n",
            "current_loss 0.3586454391479492\n",
            "Training epoch: 952/1000\n",
            "current_loss 0.35864537954330444\n",
            "Training epoch: 953/1000\n",
            "current_loss 0.35864537954330444\n",
            "Training epoch: 954/1000\n",
            "current_loss 0.35864537954330444\n",
            "Training epoch: 955/1000\n",
            "current_loss 0.35864534974098206\n",
            "Training epoch: 956/1000\n",
            "current_loss 0.3586452901363373\n",
            "Training epoch: 957/1000\n",
            "current_loss 0.3586452901363373\n",
            "Training epoch: 958/1000\n",
            "current_loss 0.3586452305316925\n",
            "Training epoch: 959/1000\n",
            "current_loss 0.3586452007293701\n",
            "Training epoch: 960/1000\n",
            "current_loss 0.3586452007293701\n",
            "Training epoch: 961/1000\n",
            "current_loss 0.35864514112472534\n",
            "Training epoch: 962/1000\n",
            "current_loss 0.35864514112472534\n",
            "Training epoch: 963/1000\n",
            "current_loss 0.35864511132240295\n",
            "Training epoch: 964/1000\n",
            "current_loss 0.35864511132240295\n",
            "Training epoch: 965/1000\n",
            "current_loss 0.35864508152008057\n",
            "Training epoch: 966/1000\n",
            "current_loss 0.3586450517177582\n",
            "Training epoch: 967/1000\n",
            "current_loss 0.3586450219154358\n",
            "Training epoch: 968/1000\n",
            "current_loss 0.3586450219154358\n",
            "Training epoch: 969/1000\n",
            "current_loss 0.3586450219154358\n",
            "Training epoch: 970/1000\n",
            "current_loss 0.35864493250846863\n",
            "Training epoch: 971/1000\n",
            "current_loss 0.35864493250846863\n",
            "Training epoch: 972/1000\n",
            "current_loss 0.358644962310791\n",
            "Training epoch: 973/1000\n",
            "current_loss 0.35864487290382385\n",
            "Training epoch: 974/1000\n",
            "current_loss 0.35864490270614624\n",
            "Training epoch: 975/1000\n",
            "current_loss 0.35864487290382385\n",
            "Training epoch: 976/1000\n",
            "current_loss 0.35864484310150146\n",
            "Training epoch: 977/1000\n",
            "current_loss 0.35864484310150146\n",
            "Training epoch: 978/1000\n",
            "current_loss 0.3586447834968567\n",
            "Training epoch: 979/1000\n",
            "current_loss 0.3586447834968567\n",
            "Training epoch: 980/1000\n",
            "current_loss 0.3586447834968567\n",
            "Training epoch: 981/1000\n",
            "current_loss 0.3586447834968567\n",
            "Training epoch: 982/1000\n",
            "current_loss 0.3586447536945343\n",
            "Training epoch: 983/1000\n",
            "current_loss 0.3586447536945343\n",
            "Training epoch: 984/1000\n",
            "current_loss 0.3586446940898895\n",
            "Training epoch: 985/1000\n",
            "current_loss 0.3586447238922119\n",
            "Training epoch: 986/1000\n",
            "current_loss 0.35864463448524475\n",
            "Training epoch: 987/1000\n",
            "current_loss 0.3586445748806\n",
            "Training epoch: 988/1000\n",
            "current_loss 0.35864460468292236\n",
            "Training epoch: 989/1000\n",
            "current_loss 0.3586445748806\n",
            "Training epoch: 990/1000\n",
            "current_loss 0.3586445450782776\n",
            "Training epoch: 991/1000\n",
            "current_loss 0.3586445450782776\n",
            "Training epoch: 992/1000\n",
            "current_loss 0.3586445748806\n",
            "Training epoch: 993/1000\n",
            "current_loss 0.3586444854736328\n",
            "Training epoch: 994/1000\n",
            "current_loss 0.3586444556713104\n",
            "Training epoch: 995/1000\n",
            "current_loss 0.3586444556713104\n",
            "Training epoch: 996/1000\n",
            "current_loss 0.35864442586898804\n",
            "Training epoch: 997/1000\n",
            "current_loss 0.35864442586898804\n",
            "Training epoch: 998/1000\n",
            "current_loss 0.35864442586898804\n",
            "Training epoch: 999/1000\n",
            "current_loss 0.35864436626434326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_df = test['median_house_value']\n",
        "X_test_df = test.drop(columns=['median_house_value'])\n",
        "X_test_df = (X_test_df - X_df.mean())/X_df.std()\n",
        "y_test_df = (y_test_df - y_test_df.mean())/y_test_df.std()"
      ],
      "metadata": {
        "id": "X8nXFN8_WUTp"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = jnp.array(X_test_df.values)\n",
        "y_test = jnp.array(y_test_df.values).reshape(-1,1)\n",
        "y_pred = jnp.dot(X_test,w) + b\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMnZwMZ2XBeZ",
        "outputId": "fdb04181-91f6-4bdf-f131-b4ae644abe17"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[-750.0598 ],\n",
              "       [-301.80548],\n",
              "       [-766.70984],\n",
              "       ...,\n",
              "       [-231.45834],\n",
              "       [  43.02465],\n",
              "       [-338.29468]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (y_pred * y_std) + y_mean\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "184GDrY4XZ8s",
        "outputId": "726944a4-88aa-4574-b0f3-442baa888397"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[-86787456.],\n",
              "       [-34797236.],\n",
              "       [-88718592.],\n",
              "       ...,\n",
              "       [-26638110.],\n",
              "       [  5197462.],\n",
              "       [-39029392.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_df = (test.drop(columns=['median_house_value']) - X_df_mean) / X_df_std\n",
        "X_test = jnp.array(X_test_df.values)\n",
        "\n",
        "y_test_actual = jnp.array(test['median_house_value'].values).reshape(-1, 1)\n",
        "\n",
        "y_pred_norm = jnp.dot(X_test, w) + b\n",
        "y_pred_usd = (y_pred_norm * y_std) + y_mean"
      ],
      "metadata": {
        "id": "UsxFPbnCYrxA"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_usd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N-_1-DjY3W5",
        "outputId": "5f92d0f5-b393-4eb9-8f78-f9b8a45c7d37"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([[352747.66],\n",
              "       [212695.33],\n",
              "       [272465.4 ],\n",
              "       ...,\n",
              "       [ 88368.49],\n",
              "       [146450.88],\n",
              "       [456648.8 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_usd = (jnp.dot(X_test, w) + b) * y_std + y_mean\n",
        "y_test_actual = (y_test * y_std) + y_mean\n",
        "\n",
        "mae = jnp.mean(jnp.abs(y_pred_usd - y_test_actual))\n",
        "\n",
        "ss_res = jnp.sum(jnp.square(y_test_actual - y_pred_usd))\n",
        "ss_tot = jnp.sum(jnp.square(y_test_actual - jnp.mean(y_test_actual)))\n",
        "r2 = 1 - (ss_res / ss_tot)\n",
        "\n",
        "print(f\"Accuracy Report:\")\n",
        "print(f\"- Average Error: ${mae:,.2f}\")\n",
        "print(f\"- Variance Explained (R2): {r2:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zulrTOP5Zjvu",
        "outputId": "54dbfde2-7d73-4029-f6cb-0c33490ec4fe"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Report:\n",
            "- Average Error: $51,496.49\n",
            "- Variance Explained (R2): 61.95%\n"
          ]
        }
      ]
    }
  ]
}